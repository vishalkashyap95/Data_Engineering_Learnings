{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2 - Week 3\n",
    "### Create a pyspark script which will read data from particular table from Mysql/Postgres database\n",
    "### Perform some operations/transformation on the data and save the result to local file storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note - Launched pyspark with below command\n",
    "# pyspark --driver-class-path .\\postgresql-42.2.18.jar --jars .\\postgresql-42.2.18.jar\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.config('spark.driver.extraClassPath', \"postgresql-42.2.18.jar\").getOrCreate()\n",
    "url = 'jdbc:postgresql://127.0.0.1/postgres'\n",
    "properties = {'user': 'postgres', 'password': 'n0ob007'}\n",
    "emp_df = spark.read.jdbc(url=url, table='Emp', properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------+\n",
      "|empname|   empdesignation|emplocation|\n",
      "+-------+-----------------+-----------+\n",
      "|   John|Software Engineer| California|\n",
      "|   Wade|    Data Engineer|    Toronto|\n",
      "| Vishal|    Data Engineer|     Mumbai|\n",
      "|   Adam|    Test Engineer|   New York|\n",
      "+-------+-----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Dataframe into RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(empname='John', empdesignation='Software Engineer', emplocation='California'),\n",
       " Row(empname='Wade', empdesignation='Data Engineer', emplocation='Toronto'),\n",
       " Row(empname='Vishal', empdesignation='Data Engineer', emplocation='Mumbai'),\n",
       " Row(empname='Adam', empdesignation='Test Engineer', emplocation='New York')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_df.rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = sc.parallelize(emp_df.rdd.map(lambda row: row.asDict()).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'empname': 'John',\n",
       "  'empdesignation': 'Software Engineer',\n",
       "  'emplocation': 'California'},\n",
       " {'empname': 'Wade',\n",
       "  'empdesignation': 'Data Engineer',\n",
       "  'emplocation': 'Toronto'},\n",
       " {'empname': 'Vishal',\n",
       "  'empdesignation': 'Data Engineer',\n",
       "  'emplocation': 'Mumbai'},\n",
       " {'empname': 'Adam',\n",
       "  'empdesignation': 'Test Engineer',\n",
       "  'emplocation': 'New York'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Software Engineer'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.collect()[0]['empdesignation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way to convert Dataframe into RDD and then convert RDD into list of dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'empname': 'John',\n",
       "  'empdesignation': 'Software Engineer',\n",
       "  'emplocation': 'California'},\n",
       " {'empname': 'Wade',\n",
       "  'empdesignation': 'Data Engineer',\n",
       "  'emplocation': 'Toronto'},\n",
       " {'empname': 'Vishal',\n",
       "  'empdesignation': 'Data Engineer',\n",
       "  'emplocation': 'Mumbai'},\n",
       " {'empname': 'Adam',\n",
       "  'empdesignation': 'Test Engineer',\n",
       "  'emplocation': 'New York'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_df.rdd.map(lambda row: row.asDict()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new column and transforming column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "# new_emp_df = emp_df.withColumnRenamed('emplocation','emp_location')\n",
    "# new_emp_df = new_emp_df.withColumnRenamed('empdesignation','emp_designation')\n",
    "# new_emp_df = new_emp_df.withColumnRenamed('empname','emp_name')\n",
    "new_emp_df = emp_df.select(\n",
    "    F.col('emplocation').alias('emp_location'),F.col('empdesignation').alias('emp_designation'),F.col('empname').alias('emp_name')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+--------+\n",
      "|emp_location|  emp_designation|emp_name|\n",
      "+------------+-----------------+--------+\n",
      "|  California|Software Engineer|    John|\n",
      "|     Toronto|    Data Engineer|    Wade|\n",
      "|      Mumbai|    Data Engineer|  Vishal|\n",
      "|    New York|    Test Engineer|    Adam|\n",
      "+------------+-----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_initials(col):\n",
    "    splitted_data = str(col).strip().split()\n",
    "    return ''.join([str(i[0]).upper() for i in splitted_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DE'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_initials(\"Data Engineer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+--------+------------+\n",
      "|emp_location|  emp_designation|emp_name|emp_desig_sf|\n",
      "+------------+-----------------+--------+------------+\n",
      "|  California|Software Engineer|    John|          SE|\n",
      "|     Toronto|    Data Engineer|    Wade|          DE|\n",
      "|      Mumbai|    Data Engineer|  Vishal|          DE|\n",
      "|    New York|    Test Engineer|    Adam|          TE|\n",
      "+------------+-----------------+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as sqlFunc\n",
    "import pyspark.sql.types as sqlTypes\n",
    "usr_def_func = sqlFunc.UserDefinedFunction(extract_initials,sqlTypes.StringType())\n",
    "transformed_emp_df = new_emp_df.withColumn('emp_desig_sf',usr_def_func('emp_designation'))\n",
    "transformed_emp_df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_emp_df.toPandas().to_csv(\"Transformed_emp_df.csv\",header=True,index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3 - Week 3\n",
    "### MoviLens dataset\n",
    "### Dataset url:https://grouplens.org/datasets/movielens/\n",
    "### Use PySpark for the followings\n",
    "### Find the Most Popular Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "links_df = pd.read_csv(\"./ml-latest-small/links.csv\")\n",
    "movies_df = pd.read_csv(\"./ml-latest-small/movies.csv\")\n",
    "ratings_df = pd.read_csv(\"./ml-latest-small/ratings.csv\")\n",
    "tags_df = pd.read_csv(\"./ml-latest-small/tags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>113497</td>\n",
       "      <td>8844.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>113228</td>\n",
       "      <td>15602.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>114885</td>\n",
       "      <td>31357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>113041</td>\n",
       "      <td>11862.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  imdbId   tmdbId\n",
       "0        1  114709    862.0\n",
       "1        2  113497   8844.0\n",
       "2        3  113228  15602.0\n",
       "3        4  114885  31357.0\n",
       "4        5  113041  11862.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>funny</td>\n",
       "      <td>1445714994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>Highly quotable</td>\n",
       "      <td>1445714996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>will ferrell</td>\n",
       "      <td>1445714992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>89774</td>\n",
       "      <td>Boxing story</td>\n",
       "      <td>1445715207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>89774</td>\n",
       "      <td>MMA</td>\n",
       "      <td>1445715200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId              tag   timestamp\n",
       "0       2    60756            funny  1445714994\n",
       "1       2    60756  Highly quotable  1445714996\n",
       "2       2    60756     will ferrell  1445714992\n",
       "3       2    89774     Boxing story  1445715207\n",
       "4       2    89774              MMA  1445715200"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 25 most Rated movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging 2 dataframe (movies and ratings)\n",
    "movies_ratings = pd.merge(movies_df,ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>847434962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1106635946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>15</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1510577970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>17</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1305696483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId             title                                       genres  \\\n",
       "0        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "1        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "2        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "3        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "4        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "\n",
       "   userId  rating   timestamp  \n",
       "0       1     4.0   964982703  \n",
       "1       5     4.0   847434962  \n",
       "2       7     4.5  1106635946  \n",
       "3      15     2.5  1510577970  \n",
       "4      17     4.5  1305696483  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PANDAS : First way to find most rated movies by using Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Forrest Gump (1994)</th>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shawshank Redemption, The (1994)</th>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulp Fiction (1994)</th>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Silence of the Lambs, The (1991)</th>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matrix, The (1999)</th>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star Wars: Episode IV - A New Hope (1977)</th>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jurassic Park (1993)</th>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Braveheart (1995)</th>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terminator 2: Judgment Day (1991)</th>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Schindler's List (1993)</th>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fight Club (1999)</th>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toy Story (1995)</th>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star Wars: Episode V - The Empire Strikes Back (1980)</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Usual Suspects, The (1995)</th>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Beauty (1999)</th>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seven (a.k.a. Se7en) (1995)</th>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Independence Day (a.k.a. ID4) (1996)</th>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apollo 13 (1995)</th>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lord of the Rings: The Fellowship of the Ring, The (2001)</th>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star Wars: Episode VI - Return of the Jedi (1983)</th>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Godfather, The (1972)</th>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fugitive, The (1993)</th>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batman (1989)</th>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saving Private Ryan (1998)</th>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Count\n",
       "title                                                    \n",
       "Forrest Gump (1994)                                   329\n",
       "Shawshank Redemption, The (1994)                      317\n",
       "Pulp Fiction (1994)                                   307\n",
       "Silence of the Lambs, The (1991)                      279\n",
       "Matrix, The (1999)                                    278\n",
       "Star Wars: Episode IV - A New Hope (1977)             251\n",
       "Jurassic Park (1993)                                  238\n",
       "Braveheart (1995)                                     237\n",
       "Terminator 2: Judgment Day (1991)                     224\n",
       "Schindler's List (1993)                               220\n",
       "Fight Club (1999)                                     218\n",
       "Toy Story (1995)                                      215\n",
       "Star Wars: Episode V - The Empire Strikes Back ...    211\n",
       "Usual Suspects, The (1995)                            204\n",
       "American Beauty (1999)                                204\n",
       "Seven (a.k.a. Se7en) (1995)                           203\n",
       "Independence Day (a.k.a. ID4) (1996)                  202\n",
       "Apollo 13 (1995)                                      201\n",
       "Raiders of the Lost Ark (Indiana Jones and the ...    200\n",
       "Lord of the Rings: The Fellowship of the Ring, ...    198\n",
       "Star Wars: Episode VI - Return of the Jedi (1983)     196\n",
       "Godfather, The (1972)                                 192\n",
       "Fugitive, The (1993)                                  190\n",
       "Batman (1989)                                         189\n",
       "Saving Private Ryan (1998)                            188"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_ratings.groupby('title').size().to_frame().rename(columns={0:'Count'}).sort_values(by='Count',ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PANDAS : 2nd way to find most rated movies by values_count() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Forrest Gump (1994)                                                               329\n",
       "Shawshank Redemption, The (1994)                                                  317\n",
       "Pulp Fiction (1994)                                                               307\n",
       "Silence of the Lambs, The (1991)                                                  279\n",
       "Matrix, The (1999)                                                                278\n",
       "Star Wars: Episode IV - A New Hope (1977)                                         251\n",
       "Jurassic Park (1993)                                                              238\n",
       "Braveheart (1995)                                                                 237\n",
       "Terminator 2: Judgment Day (1991)                                                 224\n",
       "Schindler's List (1993)                                                           220\n",
       "Fight Club (1999)                                                                 218\n",
       "Toy Story (1995)                                                                  215\n",
       "Star Wars: Episode V - The Empire Strikes Back (1980)                             211\n",
       "Usual Suspects, The (1995)                                                        204\n",
       "American Beauty (1999)                                                            204\n",
       "Seven (a.k.a. Se7en) (1995)                                                       203\n",
       "Independence Day (a.k.a. ID4) (1996)                                              202\n",
       "Apollo 13 (1995)                                                                  201\n",
       "Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)    200\n",
       "Lord of the Rings: The Fellowship of the Ring, The (2001)                         198\n",
       "Star Wars: Episode VI - Return of the Jedi (1983)                                 196\n",
       "Godfather, The (1972)                                                             192\n",
       "Fugitive, The (1993)                                                              190\n",
       "Batman (1989)                                                                     189\n",
       "Saving Private Ryan (1998)                                                        188\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_ratings['title'].value_counts().head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Pyspark\n",
    "### 1 : Read both the csv(movies.csv and ratings.csv)\n",
    "### 2 : Merge both the csv using .join method\n",
    "### 3 : converting dataframe into sql temp table and query via sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_movies_df = spark.read.csv(\"./ml-latest-small/movies.csv\",header=True)\n",
    "spark_ratings_df = spark.read.csv(\"./ml-latest-small/ratings.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "+------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_movies_df.show(5)\n",
    "spark_ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_movies_ratings_df = spark_movies_df.join(spark_ratings_df,on=['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+------+------+---------+\n",
      "|movieId|               title|              genres|userId|rating|timestamp|\n",
      "+-------+--------------------+--------------------+------+------+---------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|     1|   4.0|964982703|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|     1|   4.0|964981247|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|     1|   4.0|964982224|\n",
      "|     47|Seven (a.k.a. Se7...|    Mystery|Thriller|     1|   5.0|964983815|\n",
      "|     50|Usual Suspects, T...|Crime|Mystery|Thr...|     1|   5.0|964982931|\n",
      "|     70|From Dusk Till Da...|Action|Comedy|Hor...|     1|   3.0|964982400|\n",
      "|    101|Bottle Rocket (1996)|Adventure|Comedy|...|     1|   5.0|964980868|\n",
      "|    110|   Braveheart (1995)|    Action|Drama|War|     1|   4.0|964982176|\n",
      "|    151|      Rob Roy (1995)|Action|Drama|Roma...|     1|   5.0|964984041|\n",
      "|    157|Canadian Bacon (1...|          Comedy|War|     1|   5.0|964984100|\n",
      "+-------+--------------------+--------------------+------+------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_movies_ratings_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 way, via merging df and group by on dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               title|count|\n",
      "+--------------------+-----+\n",
      "| Forrest Gump (1994)|  329|\n",
      "|Shawshank Redempt...|  317|\n",
      "| Pulp Fiction (1994)|  307|\n",
      "|Silence of the La...|  279|\n",
      "|  Matrix, The (1999)|  278|\n",
      "|Star Wars: Episod...|  251|\n",
      "|Jurassic Park (1993)|  238|\n",
      "|   Braveheart (1995)|  237|\n",
      "|Terminator 2: Jud...|  224|\n",
      "|Schindler's List ...|  220|\n",
      "|   Fight Club (1999)|  218|\n",
      "|    Toy Story (1995)|  215|\n",
      "|Star Wars: Episod...|  211|\n",
      "|Usual Suspects, T...|  204|\n",
      "|American Beauty (...|  204|\n",
      "|Seven (a.k.a. Se7...|  203|\n",
      "|Independence Day ...|  202|\n",
      "|    Apollo 13 (1995)|  201|\n",
      "|Raiders of the Lo...|  200|\n",
      "|Lord of the Rings...|  198|\n",
      "|Star Wars: Episod...|  196|\n",
      "|Godfather, The (1...|  192|\n",
      "|Fugitive, The (1993)|  190|\n",
      "|       Batman (1989)|  189|\n",
      "|Saving Private Ry...|  188|\n",
      "+--------------------+-----+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc,col\n",
    "# spark_movies_ratings_df.groupBy('title').count().orderBy('count',ascending=False).show(25)\n",
    "spark_movies_ratings_df.groupBy('title').count().sort(col('count').desc()).show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd way via SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_movies_ratings_df.registerTempTable(\"movies_ratings_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|               title|count(title)|\n",
      "+--------------------+------------+\n",
      "| Forrest Gump (1994)|         329|\n",
      "|Shawshank Redempt...|         317|\n",
      "| Pulp Fiction (1994)|         307|\n",
      "|Silence of the La...|         279|\n",
      "|  Matrix, The (1999)|         278|\n",
      "|Star Wars: Episod...|         251|\n",
      "|Jurassic Park (1993)|         238|\n",
      "|   Braveheart (1995)|         237|\n",
      "|Terminator 2: Jud...|         224|\n",
      "|Schindler's List ...|         220|\n",
      "|   Fight Club (1999)|         218|\n",
      "|    Toy Story (1995)|         215|\n",
      "|Star Wars: Episod...|         211|\n",
      "|American Beauty (...|         204|\n",
      "|Usual Suspects, T...|         204|\n",
      "|Seven (a.k.a. Se7...|         203|\n",
      "|Independence Day ...|         202|\n",
      "|    Apollo 13 (1995)|         201|\n",
      "|Raiders of the Lo...|         200|\n",
      "|Lord of the Rings...|         198|\n",
      "|Star Wars: Episod...|         196|\n",
      "|Godfather, The (1...|         192|\n",
      "|Fugitive, The (1993)|         190|\n",
      "|       Batman (1989)|         189|\n",
      "|Saving Private Ry...|         188|\n",
      "+--------------------+------------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"select title,COUNT('title') from movies_ratings_table group by title order by 2 desc\").show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 4 \n",
    "### Spark Streaming\n",
    "### Real-time Monitoring of the Most Popular Hashtags on Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy.auth import OAuthHandler \n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial followed\n",
    "# https://towardsdatascience.com/sentiment-analysis-on-streaming-twitter-data-using-spark-structured-streaming-python-fc873684bfe3\n",
    "\n",
    "consumer_key = \"Your Key\"\n",
    "consumer_secret = \"Your Key\"\n",
    "access_token = \"Your Key\"\n",
    "access_secret = \"Your Key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|                   hashtags|\n",
      "+---------------------------+\n",
      "|             #PMCBankCrisis|\n",
      "|                #SushantDay|\n",
      "|#NUEST_JR_아론_백호_민현_렌|\n",
      "|                  #뉴이스트|\n",
      "|                     #NUEST|\n",
      "|          #BoycottBollywood|\n",
      "|                #SushantDay|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class TweetStreamer():\n",
    "    \n",
    "    def stream_tweets(self, topic_to_search):\n",
    "        tweetListner = TweetListner()\n",
    "        auth = OAuthHandler(consumer_key,consumer_secret)\n",
    "        auth.set_access_token(access_token,access_secret)\n",
    "\n",
    "        stream = Stream(auth,tweetListner)\n",
    "        stream.filter(track=topic_to_search)\n",
    "\n",
    "\n",
    "class TweetListner(StreamListener):\n",
    "    import pandas as pd    \n",
    "    from collections import namedtuple\n",
    "    fields = (\"tags\",'count')\n",
    "    Tweets_count = namedtuple('Tweeet',fields)\n",
    "    final_hashtags_list = []\n",
    "    \n",
    "    # Database connection section\n",
    "    from pyspark.sql import SparkSession\n",
    "    spark = SparkSession.builder.config('spark.driver.extraClassPath', \"postgresql-42.2.18.jar\").getOrCreate()\n",
    "    url = 'jdbc:postgresql://127.0.0.1/postgres'\n",
    "    properties = {'user': 'postgres', 'password': 'n0ob007'}\n",
    "    df = spark.read.jdbc(url=url, table='popular_hashtags', properties=properties)\n",
    "    df.show()\n",
    "    \n",
    "    # Variables for pyspark\n",
    "    from pyspark.sql.types import StructField,StringType,StructType\n",
    "    field = [\n",
    "        StructField(\"hashtags\", StringType(), True),\n",
    "    ]\n",
    "    schema = StructType(field)\n",
    "    hashtags_spark_df = spark.createDataFrame(sc.emptyRDD(),schema)\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    def on_data(self,data):\n",
    "        try:\n",
    "# #-------------Using Pandas---------------------\n",
    "#             # This piece of code, extract hashtags directly from the tweets\n",
    "#             hashTags = json.loads(data).get('entities').get('hashtags')\n",
    "#             if len(hashTags)>0:\n",
    "#                 final_hashtags = hashTags[0].get('text')\n",
    "#                 print(final_hashtags)\n",
    "                            \n",
    "#                 self.final_hashtags_list.append(final_hashtags)\n",
    "#                 print(self.pd.Series(self.final_hashtags_list).value_counts().to_frame().rename(columns={0:'Count'}).head(10))\n",
    "#                 print(\"-\"*50)\n",
    "# #-------------Till here pandas---------------------\n",
    "\n",
    "#-----------Using PySpark-----------------------\n",
    "            # This piece of code, just receive tweets in str and converts it into json and extracts text using key(text)\n",
    "            # Tweet text is then converted in to RDD and only #tags are extracted.\n",
    "            # After extracting hashtags, I am forming a pyspark dataframe and inserting it into database(postgresql. Table[popular_hashtags])\n",
    "            detailed_tweet = json.loads(data).get('text')\n",
    "#             print(detailed_tweet)\n",
    "#             print(\"Exxxx\",'extended_tweet' in detailed_tweet)\n",
    "#             if 'extended_tweet' in detailed_tweet:\n",
    "#                 tweet_full_text = detailed_tweet['extended_tweet']['full_text'].encode('utf-8')\n",
    "#             else:\n",
    "#                 tweet_full_text = detailed_tweet['text'].encode('utf-8')\n",
    "#             print(tweet_full_text)\n",
    "            twt_rdd = sc.parallelize([detailed_tweet])\n",
    "            print(\"RDD : \",twt_rdd.collect())\n",
    "            extracted_hashtags = twt_rdd.flatMap(lambda lines: lines.split(\"\\n\")).flatMap(lambda each_lines:each_lines.split(\" \")).filter(lambda x:x.lower().startswith(\"#\"))\n",
    "#             extracted_hashtags = twt_rdd.flatMap(lambda lines: self.split_lines_by(lines,\"\\n\")).collect()\n",
    "#             flatMap(lambda lines: self.split_lines_by(lines,\"\\n\"))\n",
    "#             .flatMap(lambda l:self.split_lines_by(l,\" \")).filter(lambda x:x.lower().startswith(\"#\"))\n",
    "            if extracted_hashtags.count()>0:\n",
    "                print('Count of hashtags :',extracted_hashtags.count())\n",
    "#                     [print(_ele) for _ele in extracted_hashtags.collect()]\n",
    "                for _ele in extracted_hashtags.collect():\n",
    "                    print(\"_ele --> \",_ele)\n",
    "                    row = [[_ele]]\n",
    "                    new_df = spark.createDataFrame(row)\n",
    "                    # new_df.show()\n",
    "                    self.hashtags_spark_df = self.hashtags_spark_df.union(new_df)\n",
    "#                     self.hashtags_spark_df.show()\n",
    "            self.hashtags_spark_df.show()\n",
    "            print(\"-\"*50)\n",
    "        \n",
    "            # At this line, if the pyspark dataframe count is divisible by 2 then insert in append mode in DB\n",
    "            if self.hashtags_spark_df.count() > self.counter and self.hashtags_spark_df.count()%2==0:\n",
    "                self.insert_into_db()\n",
    "                self.counter = self.hashtags_spark_df.count() + 1\n",
    "# -------------------------till here pyspark------------------------\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(\"Exception Caught while reading the data : \",str(e))\n",
    "        return True\n",
    "    \n",
    "    def on_error(self, status):\n",
    "        print(\"Error Found : \",status)\n",
    "        return True\n",
    "\n",
    "    def insert_into_db(self):\n",
    "        print(\"Inside db method : \",self.hashtags_spark_df.count())\n",
    "        self.hashtags_spark_df.write\\\n",
    "            .format(\"jdbc\")\\\n",
    "            .mode(\"append\")\\\n",
    "            .option(\"truncate\",\"true\")\\\n",
    "            .option(\"url\",self.url)\\\n",
    "            .option(\"dbtable\",\"popular_hashtags\")\\\n",
    "            .option(\"user\",\"postgres\")\\\n",
    "            .option(\"password\",\"n0ob007\").save()\n",
    "\n",
    "    def split_lines_by(lines,by):\n",
    "        print(\"inside split by lines : \",lines.split(by))\n",
    "        return lines.split(by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDD :  ['RT @mr_mayank: So Modi has openly called protesters as \"Andolan Jivi\" and said we need to save our nation from them.\\n\\nBut in reality, it is…']\n",
      "+--------+\n",
      "|hashtags|\n",
      "+--------+\n",
      "+--------+\n",
      "\n",
      "--------------------------------------------------\n",
      "RDD :  ['RT @ShaneWarne: What is going on with your cricket team ? What on Earth are they doing just letting the game drift ? Why aren’t they bowlin…']\n",
      "+--------+\n",
      "|hashtags|\n",
      "+--------+\n",
      "+--------+\n",
      "\n",
      "--------------------------------------------------\n",
      "RDD :  ['RT @ishkarnBHANDARI: PM Modi is definitely the best orator in Bharat. \\n\\nFrom Humour, Sarcasm, Factual rebuttal to setting narratives he sin…']\n",
      "+--------+\n",
      "|hashtags|\n",
      "+--------+\n",
      "+--------+\n",
      "\n",
      "--------------------------------------------------\n",
      "RDD :  ['RT @kamaalrkhan: Abki Baar Trump Sarkar! Ye Nara Diya Tha Modi Ji Ne USA main. Modi did campaign for #Trump! So if #Rihanna will campaign f…']\n",
      "Count of hashtags : 2\n",
      "_ele -->  #Trump!\n",
      "_ele -->  #Rihanna\n",
      "+--------+\n",
      "|hashtags|\n",
      "+--------+\n",
      "| #Trump!|\n",
      "|#Rihanna|\n",
      "+--------+\n",
      "\n",
      "--------------------------------------------------\n",
      "Inside db method :  2\n",
      "RDD :  ['RT @etimes: .@BeingSalmanKhan and #KatrinaKaif are all set to start shooting for ‘Tiger 3’ from next month\\n\\n#SalmanKhan \\n\\nhttps://t.co/Ywsl…']\n",
      "Count of hashtags : 2\n",
      "_ele -->  #KatrinaKaif\n",
      "_ele -->  #SalmanKhan\n",
      "+------------+\n",
      "|    hashtags|\n",
      "+------------+\n",
      "|     #Trump!|\n",
      "|    #Rihanna|\n",
      "|#KatrinaKaif|\n",
      "| #SalmanKhan|\n",
      "+------------+\n",
      "\n",
      "--------------------------------------------------\n",
      "Inside db method :  4\n",
      "RDD :  [\"RT @RememberPhoton_: Why is Bombay High Court taking so much time quashing a fake FIR on SSR's sisters?\\nQuash FIR On SSR Sisters\\nHow long S…\"]\n",
      "+------------+\n",
      "|    hashtags|\n",
      "+------------+\n",
      "|     #Trump!|\n",
      "|    #Rihanna|\n",
      "|#KatrinaKaif|\n",
      "| #SalmanKhan|\n",
      "+------------+\n",
      "\n",
      "--------------------------------------------------\n",
      "RDD :  ['RT @MansiBhandari20: India is NOT America and Modi is NOT Trump ..\\n\\nThat’s it.. that’s the tweet 🇮🇳']\n",
      "+------------+\n",
      "|    hashtags|\n",
      "+------------+\n",
      "|     #Trump!|\n",
      "|    #Rihanna|\n",
      "|#KatrinaKaif|\n",
      "| #SalmanKhan|\n",
      "+------------+\n",
      "\n",
      "--------------------------------------------------\n",
      "RDD :  ['Abki bar modi sarkar']\n",
      "+------------+\n",
      "|    hashtags|\n",
      "+------------+\n",
      "|     #Trump!|\n",
      "|    #Rihanna|\n",
      "|#KatrinaKaif|\n",
      "| #SalmanKhan|\n",
      "+------------+\n",
      "\n",
      "--------------------------------------------------\n",
      "RDD :  ['@GISALEGEND @plutoxb1j @MarcFUTTrader @FutSovereign @KieronSFF I’m sure this was due to there being no premier leag… https://t.co/LnylT3WRcU']\n",
      "+------------+\n",
      "|    hashtags|\n",
      "+------------+\n",
      "|     #Trump!|\n",
      "|    #Rihanna|\n",
      "|#KatrinaKaif|\n",
      "| #SalmanKhan|\n",
      "+------------+\n",
      "\n",
      "--------------------------------------------------\n",
      "RDD :  ['RT @dineshgrao: So many livelihoods affected, both @BJP4Goa &amp; the Modi Govt have been sitting on these issues and not taken timely decision…']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-e624c4768e38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtopic_to_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Modi'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'SSR'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'football'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'cricket'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Bollywood'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Elon musk'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mTweetStreamer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_to_search\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-39-d81bbf0d8285>\u001b[0m in \u001b[0;36mstream_tweets\u001b[1;34m(self, topic_to_search)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtweetListner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtopic_to_search\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, follow, track, is_async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filter_level'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_level\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'delimited'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'length'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_async\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_start\u001b[1;34m(self, is_async)\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                 \u001b[1;31m# This is still necessary, as a SSLError can actually be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_read_loop\u001b[1;34m(self, resp)\u001b[0m\n\u001b[0;32m    349\u001b[0m             \u001b[0mnext_status_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnext_status_obj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_status_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[1;31m# # Note: keep-alive newlines might be inserted before each length value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-d81bbf0d8285>\u001b[0m in \u001b[0;36mon_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     77\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhashtags_spark_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhashtags_spark_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;31m#                     self.hashtags_spark_df.show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhashtags_spark_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DataEngineering_Learnings\\Week_1_Task\\Spark\\spark-3.0.1-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    438\u001b[0m         \"\"\"\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DataEngineering_Learnings\\Week_1_Task\\Spark\\spark-3.0.1-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1303\u001b[1;33m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[1;32mD:\\DataEngineering_Learnings\\Week_1_Task\\Spark\\spark-3.0.1-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1033\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1034\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DataEngineering_Learnings\\Week_1_Task\\Spark\\spark-3.0.1-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1200\u001b[1;33m             \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Answer received: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "topic_to_search = ['Modi','SSR','football','cricket','Bollywood','Elon musk']\n",
    "TweetStreamer().stream_tweets(topic_to_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing popular hashtags by reading data from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|                   hashtags|\n",
      "+---------------------------+\n",
      "|             #PMCBankCrisis|\n",
      "|                #SushantDay|\n",
      "|#NUEST_JR_아론_백호_민현_렌|\n",
      "|                  #뉴이스트|\n",
      "|                     #NUEST|\n",
      "|          #BoycottBollywood|\n",
      "|                #SushantDay|\n",
      "|                    #Trump!|\n",
      "|                   #Rihanna|\n",
      "|                    #Trump!|\n",
      "|                   #Rihanna|\n",
      "|               #KatrinaKaif|\n",
      "|                #SalmanKhan|\n",
      "+---------------------------+\n",
      "\n",
      "+---------------------------+-----+\n",
      "|                   hashtags|count|\n",
      "+---------------------------+-----+\n",
      "|                #SushantDay|    2|\n",
      "|                   #Rihanna|    2|\n",
      "|                    #Trump!|    2|\n",
      "|                  #뉴이스트|    1|\n",
      "|                     #NUEST|    1|\n",
      "|                #SalmanKhan|    1|\n",
      "|          #BoycottBollywood|    1|\n",
      "|               #KatrinaKaif|    1|\n",
      "|#NUEST_JR_아론_백호_민현_렌|    1|\n",
      "|             #PMCBankCrisis|    1|\n",
      "+---------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.config('spark.driver.extraClassPath', \"postgresql-42.2.18.jar\").getOrCreate()\n",
    "url = 'jdbc:postgresql://127.0.0.1/postgres'\n",
    "properties = {'user': 'postgres', 'password': 'n0ob007'}\n",
    "popular_hashtags_df = spark.read.jdbc(url=url, table='popular_hashtags', properties=properties)\n",
    "popular_hashtags_df.show()\n",
    "\n",
    "# Grouping by hashtags\n",
    "from pyspark.sql.functions import desc,col\n",
    "popular_hashtags_df.groupBy('hashtags').count().sort(col('count').desc()).show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
